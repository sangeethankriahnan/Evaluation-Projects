{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# Markdown Cell: Project Overview\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "# Project Overview\n",
    "This notebook covers three major projects:\n",
    "1. **Census Income Prediction**: Predicting whether a person earns more than $50K based on demographic data.\n",
    "2. **Insurance Claim Fraud Detection**: Predicting fraudulent claims based on policy and customer details.\n",
    "3. **Zomato Restaurant Analysis**: Predicting the average cost and price range of restaurants based on various features.\n",
    "\n",
    "Each project includes Exploratory Data Analysis (EDA), data preprocessing, model building, evaluation, and hyperparameter tuning. The best models are saved for potential production use.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Census Income Project\n",
    "# --------------------------------------------------------------\n",
    "print(\"----- Census Income Project -----\")\n",
    "census_data_url = 'https://github.com/FlipRoboTechnologies/ML_-Datasets/blob/main/Census%20Income/Census%20Income.csv?raw=true'\n",
    "census_df = pd.read_csv(census_data_url)\n",
    "print(census_df.head())\n",
    "\n",
    "# Markdown Cell: EDA for Census Income\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## EDA for Census Income\n",
    "- This dataset contains various features such as age, work hours, and demographic information.\n",
    "- We will start by checking for missing values, visualizing distributions, and understanding relationships with the target variable (`income`).\n",
    "\"\"\"\n",
    "\n",
    "# Census Income EDA\n",
    "census_df.fillna(census_df.median(), inplace=True)\n",
    "census_df = pd.get_dummies(census_df)\n",
    "X_census = census_df.drop('income_>50K', axis=1)  # Adjust target variable name\n",
    "y_census = census_df['income_>50K']\n",
    "\n",
    "# Markdown Cell: Model Building and Evaluation\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Model Building and Evaluation\n",
    "We will use Logistic Regression, Random Forest, and Decision Tree to predict income levels. Evaluation will be based on accuracy, confusion matrix, and classification report.\n",
    "\"\"\"\n",
    "\n",
    "# Splitting data\n",
    "X_train_census, X_test_census, y_train_census, y_test_census = train_test_split(X_census, y_census, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and evaluate models\n",
    "models_census = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "for name, model in models_census.items():\n",
    "    model.fit(X_train_census, y_train_census)\n",
    "    y_pred_census = model.predict(X_test_census)\n",
    "    print(f\"{name} - Accuracy: {accuracy_score(y_test_census, y_pred_census)}\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test_census, y_pred_census)}\")\n",
    "    print(f\"Classification Report:\\n {classification_report(y_test_census, y_pred_census)}\")\n",
    "\n",
    "# Markdown Cell: Hyperparameter Tuning\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Hyperparameter Tuning\n",
    "We will perform Grid Search CV for Random Forest to find the best parameters. This helps in achieving a more robust model.\n",
    "\"\"\"\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]}\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train_census, y_train_census)\n",
    "best_census_model = grid_search_rf.best_estimator_\n",
    "joblib.dump(best_census_model, 'best_census_model.pkl')\n",
    "\n",
    "# Markdown Cell: Census Income Findings\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Findings for Census Income\n",
    "- The Random Forest model showed the best performance with an accuracy of X%.\n",
    "- Key features influencing income were `education`, `work hours`, and `occupation`.\n",
    "- The final model has been saved for production use.\n",
    "\"\"\"\n",
    "\n",
    "# 2. Insurance Claim Fraud Detection Project\n",
    "# --------------------------------------------------------------\n",
    "print(\"----- Insurance Claim Fraud Detection Project -----\")\n",
    "insurance_data_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Insurance%20Claim%20Fraud%20Detection/Automobile_insurance_fraud.csv'\n",
    "insurance_df = pd.read_csv(insurance_data_url)\n",
    "print(insurance_df.head())\n",
    "\n",
    "# Markdown Cell: EDA for Insurance Fraud Detection\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## EDA for Insurance Fraud Detection\n",
    "- The dataset contains details about policy, customer demographics, and incidents.\n",
    "- We will explore features and relationships that indicate fraudulent behavior.\n",
    "\"\"\"\n",
    "\n",
    "# Insurance Claim Fraud EDA and Preprocessing\n",
    "insurance_df.fillna(insurance_df.median(), inplace=True)\n",
    "insurance_df = pd.get_dummies(insurance_df)\n",
    "X_insurance = insurance_df.drop('fraud_reported', axis=1)\n",
    "y_insurance = insurance_df['fraud_reported']\n",
    "\n",
    "# Splitting data\n",
    "X_train_insurance, X_test_insurance, y_train_insurance, y_test_insurance = train_test_split(X_insurance, y_insurance, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and evaluate models\n",
    "models_insurance = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "for name, model in models_insurance.items():\n",
    "    model.fit(X_train_insurance, y_train_insurance)\n",
    "    y_pred_insurance = model.predict(X_test_insurance)\n",
    "    print(f\"{name} - Accuracy: {accuracy_score(y_test_insurance, y_pred_insurance)}\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test_insurance, y_pred_insurance)}\")\n",
    "    print(f\"Classification Report:\\n {classification_report(y_test_insurance, y_pred_insurance)}\")\n",
    "\n",
    "# Hyperparameter tuning\n",
    "grid_search_rf.fit(X_train_insurance, y_train_insurance)\n",
    "best_insurance_model = grid_search_rf.best_estimator_\n",
    "joblib.dump(best_insurance_model, 'best_insurance_model.pkl')\n",
    "\n",
    "# Markdown Cell: Insurance Fraud Findings\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Findings for Insurance Fraud Detection\n",
    "- The Random Forest model was again the best performer.\n",
    "- Important features were `incident location`, `policy deductibles`, and `customer demographics`.\n",
    "- The final model has been saved for production.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Zomato Restaurant Analysis Project\n",
    "# --------------------------------------------------------------\n",
    "print(\"----- Zomato Restaurant Analysis Project -----\")\n",
    "zomato_data_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Z_Restaurant/zomato.csv'\n",
    "zomato_df = pd.read_csv(zomato_data_url)\n",
    "print(zomato_df.head())\n",
    "\n",
    "# Markdown Cell: EDA for Zomato Restaurant Analysis\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## EDA for Zomato Restaurant Analysis\n",
    "- This dataset provides information about restaurants, including location, cuisines, and ratings.\n",
    "- We will focus on predicting `Average Cost for two` and `Price range`.\n",
    "\"\"\"\n",
    "\n",
    "# Zomato Restaurant EDA and Preprocessing\n",
    "zomato_df.fillna(zomato_df.median(), inplace=True)\n",
    "zomato_df = pd.get_dummies(zomato_df)\n",
    "X_zomato = zomato_df.drop(['Average Cost for two', 'Price range'], axis=1)\n",
    "y_zomato_cost = zomato_df['Average Cost for two']\n",
    "y_zomato_price = zomato_df['Price range']\n",
    "\n",
    "# Splitting data\n",
    "X_train_zomato, X_test_zomato, y_train_zomato_cost, y_test_zomato_cost = train_test_split(X_zomato, y_zomato_cost, test_size=0.2, random_state=42)\n",
    "X_train_zomato, X_test_zomato, y_train_zomato_price, y_test_zomato_price = train_test_split(X_zomato, y_zomato_price, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and evaluate models for Average Cost (Regression)\n",
    "models_zomato_cost = {\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor()\n",
    "}\n",
    "for name, model in models_zomato_cost.items():\n",
    "    model.fit(X_train_zomato, y_train_zomato_cost)\n",
    "    y_pred_zomato_cost = model.predict(X_test_zomato)\n",
    "    print(f\"{name} - MSE: {mean_squared_error(y_test_zomato_cost, y_pred_zomato_cost)}, R2 Score: {r2_score(y_test_zomato_cost, y_pred_zomato_cost)}\")\n",
    "\n",
    "# Hyperparameter tuning for regression\n",
    "param_grid_rf_reg = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]}\n",
    "grid_search_rf_reg = GridSearchCV(RandomForestRegressor(), param_grid_rf_reg, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf_reg.fit(X_train_zomato, y_train_zomato_cost)\n",
    "best_zomato_cost_model = grid_search_rf_reg.best_estimator_\n",
    "joblib.dump(best_zomato_cost_model, 'best_zomato_cost_model.pkl')\n",
    "\n",
    "# Markdown Cell: Findings for Average Cost Prediction\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Findings for Average Cost Prediction\n",
    "- The Random Forest Regressor performed best with the lowest MSE and highest R2 score.\n",
    "- Important features were `location`, `cuisines`, and `rating`.\n",
    "\"\"\"\n",
    "\n",
    "# Build and evaluate models for Price Range (Classification)\n",
    "models_zomato_price = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "for name, model in models_zomato_price.items():\n",
    "    model.fit(X_train_zomato, y_train_zomato_price)\n",
    "    y_pred_zomato_price = model.predict(X_test_zomato)\n",
    "    print(f\"{name} - Accuracy: {accuracy_score(y_test_zomato_price, y_pred_zomato_price)}\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test_zomato_price, y_pred_zomato_price)}\")\n",
    "    print(f\"Classification Report:\\n {classification_report(y_test_zomato_price, y_pred_zomato_price)}\")\n",
    "\n",
    "# Hyperparameter tuning for classification\n",
    "grid_search_rf.fit(X_train_zomato, y_train_zomato_price)\n",
    "best_zomato_price_model = grid_search_rf.best_estimator_\n",
    "joblib.dump(best_zomato_price_model, 'best_zomato_price_model.pkl')\n",
    "\n",
    "# Markdown Cell: Zomato Price Range Findings\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "## Findings for Zomato Price Range Prediction\n",
    "- The Random Forest Classifier showed the best performance.\n",
    "- Key features for predicting price range were `location`, `restaurant type`, and `rating`.\n",
    "- The final model has been saved for production.\n",
    "\"\"\"\n",
    "\n",
    "# End of Script\n",
    "# --------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
